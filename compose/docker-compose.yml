services:
  triton:
    image: nvcr.io/nvidia/tritonserver:23.10-py3
    platform: linux/amd64          # Rosetta/QEMU translates on Apple silicon
    shm_size: 1g
    volumes:
      - ../model_repository:/models
    command: >
      tritonserver --model-repository=/models --model-control-mode=poll
    ports:
      - "8000:8000"
      - "8001:8001"
